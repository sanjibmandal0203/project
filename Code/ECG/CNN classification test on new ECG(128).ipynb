{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6fbe8dde-7e1e-413c-ac3b-c83a3e38e807",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6d39ad7-cf41-4ecf-aae4-61b35913ddcf",
   "metadata": {},
   "source": [
    "# load & Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5d75302-9743-4c7c-af4e-a8576ff99ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load feature and target data\n",
    "features = pd.read_csv(r'D:\\JN\\data set\\created dataset\\ECG\\new_extracted_ECG_features.csv', header=None)  # Adjust header based on your CSV format\n",
    "targets = pd.read_csv(r'D:\\JN\\data set\\data from web\\Reference_aug.csv', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dec4d3b1-f506-47eb-ae3f-268675206e03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1975, 128)\n",
      "(1975, 2)\n"
     ]
    }
   ],
   "source": [
    "print(features.shape)\n",
    "print(targets.shape)\n",
    "\n",
    "# Extract target column\n",
    "y = targets.iloc[:, -1]  # Selecting the last column\n",
    "X = features  # All feature columns\n",
    "\n",
    "# Using .apply() method\n",
    "y = y.apply(lambda x: max(x, 0))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4f8e4819-d034-474c-afe8-1a477500fdf1",
   "metadata": {},
   "source": [
    "print(features.shape)\n",
    "features.info()\n",
    "targets.shape"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b0ea069f-6e0e-491f-bf07-1a1b3301da2f",
   "metadata": {},
   "source": [
    "features.head"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1f410e27-4101-47e5-8fb3-ecde43cca599",
   "metadata": {},
   "source": [
    "# Extract target column\n",
    "y = targets.iloc[:, -1]  # Selecting the last column\n",
    "X = features  # All feature columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "13d942ea-010c-4f8f-a572-b592e18df7de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and testing sets\n",
    "Xtrain, Xtest, Ytrain, Ytest = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ac02cba-370a-4667-babc-06d90c4ef605",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "Xtrain_scaled = scaler.fit_transform(Xtrain)\n",
    "Xtest_scaled = scaler.transform(Xtest)\n",
    "\n",
    "# Reshape data for Conv1D input\n",
    "Xtrain_reshaped = Xtrain_scaled.reshape((Xtrain_scaled.shape[0], Xtrain_scaled.shape[1], 1))\n",
    "Xtest_reshaped = Xtest_scaled.reshape((Xtest_scaled.shape[0], Xtest_scaled.shape[1], 1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db044a1e-2223-411e-9e53-d6c045036009",
   "metadata": {},
   "source": [
    "# visualize"
   ]
  },
  {
   "cell_type": "raw",
   "id": "67cca196-6b88-47d1-8c16-bb8b9963951b",
   "metadata": {},
   "source": [
    "#import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Summary stats\n",
    "print(\"Shape of Xtrain:\", Xtrain.shape)\n",
    "print(\"Mean of features:\", np.mean(Xtrain, axis=0))\n",
    "print(\"Std of features:\", np.std(Xtrain, axis=0))\n",
    "\n",
    "# Plot target distribution\n",
    "unique, counts = np.unique(Ytrain, return_counts=True)\n",
    "plt.bar(unique, counts)\n",
    "plt.title('Target Class Distribution')\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(unique)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b63c4933-3c0c-487c-951a-19a15e43e377",
   "metadata": {},
   "source": [
    "import seaborn as sns\n",
    "#import pandas as pd\n",
    "#import matplotlib.pyplot as plt\n",
    "\n",
    "# Convert Xtrain to DataFrame (assume 64 features)\n",
    "df = pd.DataFrame(Xtrain, columns=[f'feature_{i}' for i in range(Xtrain.shape[1])])\n",
    "\n",
    "# Add label column from NumPy array\n",
    "df['label'] = Ytrain  # no .iloc needed\n",
    "\n",
    "# Plot a few features colored by label\n",
    "sample_features = df.columns[:3]  # Choose first 3 features\n",
    "sns.pairplot(df, vars=sample_features, hue='label', palette='Set1')\n",
    "plt.suptitle('Pairplot of Sample Features by Class', y=1.02)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "634e15b3-0a75-4a7b-ab03-ed7d7f156be6",
   "metadata": {},
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(Xtrain)\n",
    "\n",
    "# PCA to 2D\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "# Plot (fix: no .iloc â€” Ytrain is a NumPy array)\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(X_pca[:, 0], X_pca[:, 1], c=Ytrain, cmap='coolwarm', alpha=0.7)\n",
    "plt.title('2D PCA Projection of Training Data')\n",
    "plt.xlabel('PCA 1')\n",
    "plt.ylabel('PCA 2')\n",
    "plt.colorbar(label='Class')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d8ce616-fca6-4d1a-90cd-7a6bda905c1c",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "raw",
   "id": "40592e8d-03b5-4e5e-bf77-60d943df7e9a",
   "metadata": {},
   "source": [
    "# normalize\n",
    "scaler = StandardScaler()\n",
    "Xtrain = scaler.fit_transform(Xtrain)\n",
    "Xtest = scaler.transform(Xtest)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7bc756dc-4b81-48ec-a1d6-3344f62ea905",
   "metadata": {},
   "source": [
    "# Reshape for Conv1D: (samples, time steps, features) â€” we'll assume 128 time steps, 1 feature each\n",
    "Xtrain = Xtrain.reshape((Xtrain.shape[0], Xtrain.shape[1], 1))\n",
    "Xtest = Xtest.reshape((Xtest.shape[0], Xtest.shape[1], 1))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "83ba83fd-1cb0-43c9-b589-e01cc59e8878",
   "metadata": {},
   "source": [
    "#Convert labels to binary class format (if not already 0 or 1)\n",
    "Ytrain = to_categorical(Ytrain)\n",
    "Ytest = to_categorical(Ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4c35f72-b75a-4d16-9f92-01c209db93db",
   "metadata": {},
   "source": [
    "# CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fdd6ec3f-878f-4a3f-b5eb-9108ef5439ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv1D, Flatten, Dense, Input\n",
    "\n",
    "model = Sequential([\n",
    "    Input(shape=(128, 1)),  # ðŸ‘ˆ Explicit Input layer\n",
    "    Conv1D(filters=8, kernel_size=2, activation='relu'),\n",
    "    Conv1D(filters=8, kernel_size=2, activation='relu'),\n",
    "    Conv1D(filters=8, kernel_size=2, activation='relu'),\n",
    "    Conv1D(filters=8, kernel_size=2, activation='relu'),\n",
    "    Flatten(),\n",
    "    Dense(8, activation='relu'),\n",
    "    Dense(2, activation='softmax')  # 2 output classes for binary classification\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "13bbf0aa-e27a-4bd6-ade5-ead28e76fcf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Arguments `target` and `output` must have the same shape. Received: target.shape=(8, 1), output.shape=(8, 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m history = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mYtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m8\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.2\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n\u001b[32m    120\u001b[39m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[32m    121\u001b[39m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m122\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e.with_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    123\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    124\u001b[39m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\nn.py:660\u001b[39m, in \u001b[36mcategorical_crossentropy\u001b[39m\u001b[34m(target, output, from_logits, axis)\u001b[39m\n\u001b[32m    658\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m e1, e2 \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(target.shape, output.shape):\n\u001b[32m    659\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m e1 \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m e2 \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m e1 != e2:\n\u001b[32m--> \u001b[39m\u001b[32m660\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    661\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mArguments `target` and `output` must have the same shape. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    662\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mReceived: \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    663\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mtarget.shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, output.shape=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    664\u001b[39m         )\n\u001b[32m    666\u001b[39m output, from_logits = _get_logits(\n\u001b[32m    667\u001b[39m     output, from_logits, \u001b[33m\"\u001b[39m\u001b[33mSoftmax\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mcategorical_crossentropy\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    668\u001b[39m )\n\u001b[32m    669\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m from_logits:\n",
      "\u001b[31mValueError\u001b[39m: Arguments `target` and `output` must have the same shape. Received: target.shape=(8, 1), output.shape=(8, 2)"
     ]
    }
   ],
   "source": [
    "history = model.fit(Xtrain, Ytrain, epochs=5, batch_size=8, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bea1181-3258-4679-846f-eb91155e9bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy = model.evaluate(Xtest, Ytest)\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1aa348-1271-4576-9c6d-eda5560dcd1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot accuracy\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "# Plot loss\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fcd747b-7a0f-4747-8664-4b0442adf670",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5671bd55-0920-475e-8a78-5f2b87d4f7eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
