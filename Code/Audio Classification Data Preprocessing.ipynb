{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94cf7f4c-e4c9-4782-a434-7b4c2e9263a0",
   "metadata": {},
   "source": [
    "### Let's read asample audio using librosa\n",
    "import librosa\n",
    "audio_file_path=\"test2/a0008.wav\"\n",
    "librosa_audio_data, librosa_sample_rate=librosa.load(audio_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5095ee6c-4f5e-4555-9f9d-e5bb1f1deae7",
   "metadata": {},
   "source": [
    "print(librosa_audio_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d730097f-a3e8-4258-b097-2a9ee4f8d765",
   "metadata": {},
   "source": [
    "### lets plot the librosa audio data\n",
    "import matplotlib.pyplot as plt\n",
    "# Original audio with one channel\n",
    "plt.figure(figsize=(12,4))\n",
    "plt.plot(librosa_audio_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a680557-38cb-408c-a259-a60c1c26bbd3",
   "metadata": {},
   "source": [
    "### ets read with scipy\n",
    "from scipy.io import wavfile as wav\n",
    "wave_sample_rate, wave_audio = wav.read(audio_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "375d27f5-7100-4ff9-8730-0fef0c859936",
   "metadata": {},
   "source": [
    "wave_audio\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c106ee40-28fb-43d6-9957-03aa82614415",
   "metadata": {},
   "source": [
    "plt.plot(wave_audio)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb758ec0-5a07-491a-acd5-5b267f3c0206",
   "metadata": {},
   "source": [
    "## Extract features\n",
    "## MFCC - Mel Frequency Ceostrl Coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d45fdcc-2d14-4daa-ade4-f7ff3bcc2ae0",
   "metadata": {},
   "source": [
    "mfccs = librosa.feature.mfcc(y=librosa_audio_data, sr=librosa_sample_rate, n_mfcc=40)\n",
    "print(mfccs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da56ae1-fcc2-4e46-9c26-2f6fcb66a724",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "mfccs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "519e0b8c-3644-4f54-a615-309de9efe8de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>fname</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>set_a2/a0001</td>\n",
       "      <td>a0001</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>set_a2/a0002</td>\n",
       "      <td>a0002</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>set_a2/a0003</td>\n",
       "      <td>a0003</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>set_a2/a0004</td>\n",
       "      <td>a0004</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>set_a2/a0005</td>\n",
       "      <td>a0005</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0  fname  label\n",
       "0  set_a2/a0001  a0001      1\n",
       "1  set_a2/a0002  a0002      1\n",
       "2  set_a2/a0003  a0003      1\n",
       "3  set_a2/a0004  a0004      1\n",
       "4  set_a2/a0005  a0005      1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Extracting MFCC's for every audio file\n",
    "import pandas as pd\n",
    "import os\n",
    "import librosa\n",
    "\n",
    "audio_dataset_path='E:/JN/test2/audio2/set_a2'\n",
    "metadata=pd.read_csv('E:/JN/test2/metadata2/set_a2.csv')\n",
    "metadata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "13ba0d27-8ee8-4e69-be3d-996c84a7e6ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def features_extractor(file_name):\n",
    "    audio, sample_rate = librosa.load(file_name, res_type='kaiser_fast')\n",
    "    mfccs_features = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=60) #40\n",
    "    mfccs_scaled_features = np.mean(mfccs_features.T, axis=0)\n",
    "\n",
    "    return mfccs_scaled_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c9f5fb3-d045-4aec-b69d-9c842b1dcf2e",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "## Now we itaerate through every audio file and extract features\n",
    "## using MelFrequency Capstral Coefficients\n",
    "extracted_features=[]\n",
    "for index_num,row in tqdm(metadata.iterrows()):\n",
    "    file_name = os.path.join(os.path.abspath(audio_dataset_path),'fold'+str(row[\"fold\"])+'/',str(row[\"dataset\"]))\n",
    "    final_class_labels=row[\"class\"]\n",
    "    data=features_extractor(file_name)\n",
    "    extracted_features.append([data,final_class_labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "15def9c4-1d7b-4212-9557-971a4c54c199",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "409it [02:26,  2.79it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Ensure 'fold' column exists\n",
    "#if \"set_a\" not in metadata.columns:\n",
    "    ## metadata[\"set_a\"] = 1  # Assign set_a if missing\n",
    "\n",
    "extracted_features = []\n",
    "for index_num, row in tqdm(metadata.iterrows()):\n",
    "    file_name = os.path.join(os.path.abspath(audio_dataset_path), str(row[\"fname\"]))\n",
    "    final_class_labels = row[\"label\"]\n",
    "    data = features_extractor(file_name)\n",
    "    extracted_features.append([data, final_class_labels])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "10e5c9c1-59ea-4624-ad97-7f97f2b58cd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[-576.862, 117.566956, 82.46526, 40.06241, 6.2...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[-627.9096, 137.26224, 100.36392, 55.458004, 1...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[-600.3022, 78.11143, 61.655224, 41.402103, 24...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[-561.78186, 89.5558, 71.56037, 48.790478, 28....</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[-488.9869, 66.22584, 57.067467, 44.92165, 33....</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             feature  label\n",
       "0  [-576.862, 117.566956, 82.46526, 40.06241, 6.2...      1\n",
       "1  [-627.9096, 137.26224, 100.36392, 55.458004, 1...      1\n",
       "2  [-600.3022, 78.11143, 61.655224, 41.402103, 24...      1\n",
       "3  [-561.78186, 89.5558, 71.56037, 48.790478, 28....      1\n",
       "4  [-488.9869, 66.22584, 57.067467, 44.92165, 33....      1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### converting extracted_features to pandas dataframe\n",
    "extracted_features_df=pd.DataFrame(extracted_features,columns=['feature','label'])\n",
    "extracted_features_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e3ee1c2d-defa-43d0-91db-8dcf1e8d6b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "### split the data set into independent and dependent data set\n",
    "X=np.array(extracted_features_df['feature'].tolist())\n",
    "y=np.array(extracted_features_df['label'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "90b0d51b-515e-4843-927b-d08f82844602",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(409, 60)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7760d48f-907a-4cd3-a24b-3ff29d28fe6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### lable encoding\n",
    "y=np.array(pd.get_dummies(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cb874919-15bf-498d-894d-6f7df4fdbc46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(409, 2)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7eb7d245-fad0-41fd-b02d-8b44d2b07ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Train Test Split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test=train_test_split(X,y,test_size=0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b3183197-6ab3-4eff-81ae-12ef63fe6aac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-5.32053284e+02,  1.00983185e+02,  8.10520935e+01, ...,\n",
       "         4.85098153e-01,  3.19794297e-01,  2.06919894e-01],\n",
       "       [-6.33564087e+02,  1.13562866e+02,  8.87439651e+01, ...,\n",
       "         4.43876609e-02,  1.48502275e-01,  4.64142203e-01],\n",
       "       [-5.15414429e+02,  6.98661804e+01,  6.10277100e+01, ...,\n",
       "         4.26915661e-02,  2.23498251e-02, -1.68924201e-02],\n",
       "       ...,\n",
       "       [-4.10968842e+02,  6.58098145e+01,  5.94201889e+01, ...,\n",
       "         7.63589470e-03,  1.46610603e-01,  2.51174033e-01],\n",
       "       [-4.88784485e+02,  8.02808762e+01,  6.18809967e+01, ...,\n",
       "        -1.84428930e-01, -1.37102640e+00, -8.21092248e-01],\n",
       "       [-5.75637756e+02,  8.14631348e+01,  6.53264923e+01, ...,\n",
       "         4.29263413e-01,  7.02222064e-02, -1.81809485e-01]], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b4b81981-9343-49a3-9028-110f3898ca54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(327, 60)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "10eb2bcf-4f56-4a86-9a96-bb2cd29bf2ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [False,  True],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [ True, False],\n",
       "       [ True, False]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bac21f08-cd30-4911-8950-cd0d20d95685",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(82, 60)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9d9c043b-b34a-48a9-9a9f-aac579229961",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cd35d94b-bb47-4160-adbe-bb9cff5417c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "39ef5ee6-f286-409c-b939-602d57bb66e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.18.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "866f0994-30d5-4cd0-85d9-430aa687812d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Dropout,Activation,Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "55e1a59b-0ded-4e18-9664-3d1a0c7fb4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## number of class\n",
    "num_labls=y.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "284ab418-f5ea-44cd-87fc-1357735a36be",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Dense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "76416bee-d14f-4b5c-9558-7e906853c150",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model=Sequential()\n",
    "## first layer\n",
    "model.add(Dense(256,input_shape=(60,))) #100 40\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "## second layer\n",
    "model.add(Dense(512)) #200\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "## third layer\n",
    "model.add(Dense(256))  #100\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "## final layer\n",
    "model.add(Dense(num_labls))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a9770acc-2b43-4c5e-bc6c-72bf7d9b5a47",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">15,616</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">131,584</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">514</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)                   │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │          \u001b[38;5;34m15,616\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation (\u001b[38;5;33mActivation\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                 │         \u001b[38;5;34m131,584\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_1 (\u001b[38;5;33mActivation\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │         \u001b[38;5;34m131,328\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_2 (\u001b[38;5;33mActivation\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)                   │             \u001b[38;5;34m514\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ activation_3 (\u001b[38;5;33mActivation\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)                   │               \u001b[38;5;34m0\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">279,042</span> (1.06 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m279,042\u001b[0m (1.06 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">279,042</span> (1.06 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m279,042\u001b[0m (1.06 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "73956d3f-00ea-42e0-a453-0d3b87e6bf05",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',metrics=['accuracy'],optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bdce5029-c5e0-42ce-a7f6-5d870aeb1908",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m4/6\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5322 - loss: 34.1249\n",
      "Epoch 1: val_loss improved from inf to 12.36771, saving model to saved_models/audio_classification.keras\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 113ms/step - accuracy: 0.5448 - loss: 32.5585 - val_accuracy: 0.7073 - val_loss: 12.3677\n",
      "Epoch 2/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6122 - loss: 18.5317\n",
      "Epoch 2: val_loss improved from 12.36771 to 0.74593, saving model to saved_models/audio_classification.keras\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.6086 - loss: 18.7029 - val_accuracy: 0.6341 - val_loss: 0.7459\n",
      "Epoch 3/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5821 - loss: 16.8238\n",
      "Epoch 3: val_loss did not improve from 0.74593\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.5850 - loss: 16.8234 - val_accuracy: 0.7073 - val_loss: 4.2799\n",
      "Epoch 4/200\n",
      "\u001b[1m5/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6071 - loss: 12.4478\n",
      "Epoch 4: val_loss improved from 0.74593 to 0.64697, saving model to saved_models/audio_classification.keras\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.6093 - loss: 12.5132 - val_accuracy: 0.7317 - val_loss: 0.6470\n",
      "Epoch 5/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5915 - loss: 9.6878 \n",
      "Epoch 5: val_loss did not improve from 0.64697\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.5891 - loss: 9.7372 - val_accuracy: 0.7073 - val_loss: 2.2697\n",
      "Epoch 6/200\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.5312 - loss: 13.5654\n",
      "Epoch 6: val_loss did not improve from 0.64697\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.5969 - loss: 11.6406 - val_accuracy: 0.7073 - val_loss: 2.8939\n",
      "Epoch 7/200\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.6562 - loss: 10.0569\n",
      "Epoch 7: val_loss improved from 0.64697 to 0.60883, saving model to saved_models/audio_classification.keras\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.6166 - loss: 9.7981 - val_accuracy: 0.6463 - val_loss: 0.6088\n",
      "Epoch 8/200\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.5156 - loss: 9.3708\n",
      "Epoch 8: val_loss did not improve from 0.60883\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.5665 - loss: 8.0708 - val_accuracy: 0.7073 - val_loss: 1.6440\n",
      "Epoch 9/200\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.5156 - loss: 10.9188\n",
      "Epoch 9: val_loss did not improve from 0.60883\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.5984 - loss: 7.8530 - val_accuracy: 0.7073 - val_loss: 0.8450\n",
      "Epoch 10/200\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.5625 - loss: 8.0287\n",
      "Epoch 10: val_loss did not improve from 0.60883\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.6170 - loss: 5.6858 - val_accuracy: 0.7073 - val_loss: 1.0992\n",
      "Epoch 11/200\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.6406 - loss: 4.4915\n",
      "Epoch 11: val_loss did not improve from 0.60883\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.6353 - loss: 4.6348 - val_accuracy: 0.7073 - val_loss: 1.3950\n",
      "Epoch 12/200\n",
      "\u001b[1m5/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5976 - loss: 5.6724\n",
      "Epoch 12: val_loss did not improve from 0.60883\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6025 - loss: 5.5509 - val_accuracy: 0.7073 - val_loss: 0.8664\n",
      "Epoch 13/200\n",
      "\u001b[1m4/6\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.6055 - loss: 4.2345\n",
      "Epoch 13: val_loss improved from 0.60883 to 0.54344, saving model to saved_models/audio_classification.keras\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.5972 - loss: 4.2268 - val_accuracy: 0.7195 - val_loss: 0.5434\n",
      "Epoch 14/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6015 - loss: 4.2170\n",
      "Epoch 14: val_loss improved from 0.54344 to 0.53400, saving model to saved_models/audio_classification.keras\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.6038 - loss: 4.1304 - val_accuracy: 0.7561 - val_loss: 0.5340\n",
      "Epoch 15/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6170 - loss: 3.3018\n",
      "Epoch 15: val_loss did not improve from 0.53400\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6149 - loss: 3.3098 - val_accuracy: 0.7073 - val_loss: 0.6336\n",
      "Epoch 16/200\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.5625 - loss: 4.4409\n",
      "Epoch 16: val_loss did not improve from 0.53400\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.6268 - loss: 3.3191 - val_accuracy: 0.7073 - val_loss: 0.6547\n",
      "Epoch 17/200\n",
      "\u001b[1m5/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6153 - loss: 2.8369 \n",
      "Epoch 17: val_loss did not improve from 0.53400\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.6133 - loss: 2.8959 - val_accuracy: 0.7073 - val_loss: 0.5600\n",
      "Epoch 18/200\n",
      "\u001b[1m5/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5736 - loss: 2.8646 \n",
      "Epoch 18: val_loss did not improve from 0.53400\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.5819 - loss: 2.8867 - val_accuracy: 0.7439 - val_loss: 0.5717\n",
      "Epoch 19/200\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 172ms/step - accuracy: 0.5000 - loss: 3.6031\n",
      "Epoch 19: val_loss did not improve from 0.53400\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.5800 - loss: 3.0509 - val_accuracy: 0.6829 - val_loss: 0.6211\n",
      "Epoch 20/200\n",
      "\u001b[1m5/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6062 - loss: 1.9791 \n",
      "Epoch 20: val_loss did not improve from 0.53400\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.6139 - loss: 1.9593 - val_accuracy: 0.7439 - val_loss: 0.6176\n",
      "Epoch 21/200\n",
      "\u001b[1m5/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5324 - loss: 2.2100 \n",
      "Epoch 21: val_loss did not improve from 0.53400\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.5437 - loss: 2.1421 - val_accuracy: 0.7073 - val_loss: 0.5879\n",
      "Epoch 22/200\n",
      "\u001b[1m5/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6048 - loss: 2.3100\n",
      "Epoch 22: val_loss did not improve from 0.53400\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.6067 - loss: 2.2633 - val_accuracy: 0.7073 - val_loss: 0.5823\n",
      "Epoch 23/200\n",
      "\u001b[1m5/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6528 - loss: 1.5280\n",
      "Epoch 23: val_loss did not improve from 0.53400\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.6454 - loss: 1.5480 - val_accuracy: 0.7073 - val_loss: 0.6439\n",
      "Epoch 24/200\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.6406 - loss: 1.7552\n",
      "Epoch 24: val_loss did not improve from 0.53400\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.5939 - loss: 1.9319 - val_accuracy: 0.3902 - val_loss: 0.6945\n",
      "Epoch 25/200\n",
      "\u001b[1m5/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5619 - loss: 1.9851\n",
      "Epoch 25: val_loss did not improve from 0.53400\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.5691 - loss: 1.9018 - val_accuracy: 0.3415 - val_loss: 0.6981\n",
      "Epoch 26/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5651 - loss: 1.8292\n",
      "Epoch 26: val_loss did not improve from 0.53400\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.5700 - loss: 1.7912 - val_accuracy: 0.3049 - val_loss: 0.7055\n",
      "Epoch 27/200\n",
      "\u001b[1m5/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5882 - loss: 1.6264\n",
      "Epoch 27: val_loss did not improve from 0.53400\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.6010 - loss: 1.5455 - val_accuracy: 0.2927 - val_loss: 0.7544\n",
      "Epoch 28/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6310 - loss: 1.1438 \n",
      "Epoch 28: val_loss did not improve from 0.53400\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6291 - loss: 1.1427 - val_accuracy: 0.2927 - val_loss: 0.7618\n",
      "Epoch 29/200\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 185ms/step - accuracy: 0.5781 - loss: 1.2402\n",
      "Epoch 29: val_loss did not improve from 0.53400\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.6126 - loss: 1.1883 - val_accuracy: 0.2927 - val_loss: 0.7399\n",
      "Epoch 30/200\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.6094 - loss: 1.4064\n",
      "Epoch 30: val_loss did not improve from 0.53400\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.6076 - loss: 1.2485 - val_accuracy: 0.2927 - val_loss: 0.7156\n",
      "Epoch 31/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6316 - loss: 1.0595\n",
      "Epoch 31: val_loss did not improve from 0.53400\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.6305 - loss: 1.0551 - val_accuracy: 0.7073 - val_loss: 0.6726\n",
      "Epoch 32/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6619 - loss: 1.1322 \n",
      "Epoch 32: val_loss did not improve from 0.53400\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.6621 - loss: 1.1249 - val_accuracy: 0.7073 - val_loss: 0.6429\n",
      "Epoch 33/200\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.6250 - loss: 1.1451\n",
      "Epoch 33: val_loss did not improve from 0.53400\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.6506 - loss: 1.1032 - val_accuracy: 0.7073 - val_loss: 0.6741\n",
      "Epoch 34/200\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 166ms/step - accuracy: 0.7344 - loss: 0.6667\n",
      "Epoch 34: val_loss did not improve from 0.53400\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7114 - loss: 0.7703 - val_accuracy: 0.6098 - val_loss: 0.6908\n",
      "Epoch 35/200\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.6406 - loss: 0.7255\n",
      "Epoch 35: val_loss did not improve from 0.53400\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.6343 - loss: 0.8958 - val_accuracy: 0.5610 - val_loss: 0.6927\n",
      "Epoch 36/200\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.6719 - loss: 0.7626\n",
      "Epoch 36: val_loss did not improve from 0.53400\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.6601 - loss: 0.7751 - val_accuracy: 0.5610 - val_loss: 0.6919\n",
      "Epoch 37/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6272 - loss: 0.8035 \n",
      "Epoch 37: val_loss did not improve from 0.53400\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6289 - loss: 0.7981 - val_accuracy: 0.6707 - val_loss: 0.6881\n",
      "Epoch 38/200\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.6250 - loss: 0.7978\n",
      "Epoch 38: val_loss did not improve from 0.53400\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.5972 - loss: 0.9187 - val_accuracy: 0.6951 - val_loss: 0.6852\n",
      "Epoch 39/200\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.6094 - loss: 0.9378\n",
      "Epoch 39: val_loss did not improve from 0.53400\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.6451 - loss: 0.8460 - val_accuracy: 0.7073 - val_loss: 0.6781\n",
      "Epoch 40/200\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.5781 - loss: 1.0863\n",
      "Epoch 40: val_loss did not improve from 0.53400\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.6424 - loss: 0.8479 - val_accuracy: 0.7073 - val_loss: 0.6763\n",
      "Epoch 41/200\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.5312 - loss: 1.3378\n",
      "Epoch 41: val_loss did not improve from 0.53400\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.6519 - loss: 0.9261 - val_accuracy: 0.7073 - val_loss: 0.6671\n",
      "Epoch 42/200\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.6562 - loss: 0.9338\n",
      "Epoch 42: val_loss did not improve from 0.53400\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.6577 - loss: 0.8246 - val_accuracy: 0.7073 - val_loss: 0.6649\n",
      "Epoch 43/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6697 - loss: 0.8722\n",
      "Epoch 43: val_loss did not improve from 0.53400\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6719 - loss: 0.8683 - val_accuracy: 0.7073 - val_loss: 0.6708\n",
      "Epoch 44/200\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.5625 - loss: 0.9342\n",
      "Epoch 44: val_loss did not improve from 0.53400\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.6232 - loss: 0.7913 - val_accuracy: 0.7073 - val_loss: 0.6672\n",
      "Epoch 45/200\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.7031 - loss: 0.6030\n",
      "Epoch 45: val_loss did not improve from 0.53400\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.6913 - loss: 0.6651 - val_accuracy: 0.7073 - val_loss: 0.6683\n",
      "Epoch 46/200\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.6406 - loss: 0.8332\n",
      "Epoch 46: val_loss did not improve from 0.53400\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.6630 - loss: 0.7745 - val_accuracy: 0.7073 - val_loss: 0.6661\n",
      "Epoch 47/200\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.6094 - loss: 0.7940\n",
      "Epoch 47: val_loss did not improve from 0.53400\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.6826 - loss: 0.7136 - val_accuracy: 0.7073 - val_loss: 0.6603\n",
      "Epoch 48/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7068 - loss: 0.7628\n",
      "Epoch 48: val_loss did not improve from 0.53400\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7020 - loss: 0.7629 - val_accuracy: 0.7073 - val_loss: 0.6483\n",
      "Epoch 49/200\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.6875 - loss: 0.8788\n",
      "Epoch 49: val_loss did not improve from 0.53400\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.6889 - loss: 0.7714 - val_accuracy: 0.7073 - val_loss: 0.6403\n",
      "Epoch 50/200\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.7969 - loss: 0.4915\n",
      "Epoch 50: val_loss did not improve from 0.53400\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.6908 - loss: 0.6520 - val_accuracy: 0.7073 - val_loss: 0.6361\n",
      "Epoch 51/200\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.7031 - loss: 0.6659\n",
      "Epoch 51: val_loss did not improve from 0.53400\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.6886 - loss: 0.6664 - val_accuracy: 0.7073 - val_loss: 0.6468\n",
      "Epoch 52/200\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.7500 - loss: 0.6178\n",
      "Epoch 52: val_loss did not improve from 0.53400\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7078 - loss: 0.6817 - val_accuracy: 0.7073 - val_loss: 0.6491\n",
      "Epoch 53/200\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.6562 - loss: 0.6475\n",
      "Epoch 53: val_loss did not improve from 0.53400\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.6668 - loss: 0.7096 - val_accuracy: 0.7073 - val_loss: 0.6485\n",
      "Epoch 54/200\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.5469 - loss: 0.9879\n",
      "Epoch 54: val_loss did not improve from 0.53400\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.6400 - loss: 0.8091 - val_accuracy: 0.7073 - val_loss: 0.6527\n",
      "Epoch 55/200\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.7031 - loss: 0.5529\n",
      "Epoch 55: val_loss did not improve from 0.53400\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6788 - loss: 0.6153 - val_accuracy: 0.7073 - val_loss: 0.6574\n",
      "Epoch 56/200\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.6250 - loss: 0.6438\n",
      "Epoch 56: val_loss did not improve from 0.53400\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6626 - loss: 0.6809 - val_accuracy: 0.7073 - val_loss: 0.6644\n",
      "Epoch 57/200\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.6250 - loss: 0.7573\n",
      "Epoch 57: val_loss did not improve from 0.53400\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6647 - loss: 0.6861 - val_accuracy: 0.7073 - val_loss: 0.6754\n",
      "Epoch 58/200\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.6562 - loss: 0.6434\n",
      "Epoch 58: val_loss did not improve from 0.53400\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.6933 - loss: 0.6471 - val_accuracy: 0.7073 - val_loss: 0.6812\n",
      "Epoch 59/200\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.7188 - loss: 0.5989\n",
      "Epoch 59: val_loss did not improve from 0.53400\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7055 - loss: 0.6567 - val_accuracy: 0.7073 - val_loss: 0.6861\n",
      "Epoch 60/200\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.7344 - loss: 0.6377\n",
      "Epoch 60: val_loss did not improve from 0.53400\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.6765 - loss: 0.6546 - val_accuracy: 0.7073 - val_loss: 0.6833\n",
      "Epoch 61/200\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.7344 - loss: 0.6022\n",
      "Epoch 61: val_loss did not improve from 0.53400\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7238 - loss: 0.6160 - val_accuracy: 0.7073 - val_loss: 0.6739\n",
      "Epoch 62/200\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.6875 - loss: 0.6296\n",
      "Epoch 62: val_loss did not improve from 0.53400\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.6900 - loss: 0.6140 - val_accuracy: 0.7073 - val_loss: 0.6652\n",
      "Epoch 63/200\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.7188 - loss: 0.7395\n",
      "Epoch 63: val_loss did not improve from 0.53400\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.7078 - loss: 0.6876 - val_accuracy: 0.7073 - val_loss: 0.6597\n",
      "Epoch 64/200\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.7188 - loss: 0.6686\n",
      "Epoch 64: val_loss did not improve from 0.53400\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.7010 - loss: 0.6608 - val_accuracy: 0.7073 - val_loss: 0.6626\n",
      "Epoch 65/200\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.7344 - loss: 0.6076\n",
      "Epoch 65: val_loss did not improve from 0.53400\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.6924 - loss: 0.6986 - val_accuracy: 0.7073 - val_loss: 0.6637\n",
      "Epoch 66/200\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.5625 - loss: 0.8860\n",
      "Epoch 66: val_loss did not improve from 0.53400\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6494 - loss: 0.7350 - val_accuracy: 0.7073 - val_loss: 0.6677\n",
      "Epoch 67/200\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.7812 - loss: 0.5230\n",
      "Epoch 67: val_loss did not improve from 0.53400\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7153 - loss: 0.6246 - val_accuracy: 0.7073 - val_loss: 0.6631\n",
      "Epoch 68/200\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.6562 - loss: 0.6342\n",
      "Epoch 68: val_loss did not improve from 0.53400\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.6702 - loss: 0.6385 - val_accuracy: 0.7073 - val_loss: 0.6603\n",
      "Epoch 69/200\n",
      "\u001b[1m5/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6521 - loss: 0.7044 \n",
      "Epoch 69: val_loss did not improve from 0.53400\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.6589 - loss: 0.6912 - val_accuracy: 0.7073 - val_loss: 0.6461\n",
      "Epoch 70/200\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.7188 - loss: 0.6395\n",
      "Epoch 70: val_loss did not improve from 0.53400\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7031 - loss: 0.6847 - val_accuracy: 0.7073 - val_loss: 0.6496\n",
      "Epoch 71/200\n",
      "\u001b[1m5/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7052 - loss: 0.6312\n",
      "Epoch 71: val_loss did not improve from 0.53400\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.7003 - loss: 0.6372 - val_accuracy: 0.7073 - val_loss: 0.6592\n",
      "Epoch 72/200\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - accuracy: 0.7031 - loss: 0.6357\n",
      "Epoch 72: val_loss did not improve from 0.53400\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6667 - loss: 0.6445 - val_accuracy: 0.7073 - val_loss: 0.6661\n",
      "Epoch 73/200\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 170ms/step - accuracy: 0.7500 - loss: 0.6617\n",
      "Epoch 73: val_loss did not improve from 0.53400\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.6966 - loss: 0.7012 - val_accuracy: 0.7073 - val_loss: 0.6588\n",
      "Epoch 74/200\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.7656 - loss: 0.6047\n",
      "Epoch 74: val_loss did not improve from 0.53400\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7165 - loss: 0.6460 - val_accuracy: 0.7073 - val_loss: 0.6443\n",
      "Epoch 75/200\n",
      "\u001b[1m4/6\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.6576 - loss: 0.7233 \n",
      "Epoch 75: val_loss did not improve from 0.53400\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.6736 - loss: 0.7012 - val_accuracy: 0.7073 - val_loss: 0.6429\n",
      "Epoch 76/200\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.7344 - loss: 0.5821\n",
      "Epoch 76: val_loss did not improve from 0.53400\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.6929 - loss: 0.6284 - val_accuracy: 0.7073 - val_loss: 0.6411\n",
      "Epoch 77/200\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.7188 - loss: 0.6511\n",
      "Epoch 77: val_loss did not improve from 0.53400\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7185 - loss: 0.6164 - val_accuracy: 0.7073 - val_loss: 0.6430\n",
      "Epoch 78/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6995 - loss: 0.6628 \n",
      "Epoch 78: val_loss did not improve from 0.53400\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6991 - loss: 0.6595 - val_accuracy: 0.7073 - val_loss: 0.6290\n",
      "Epoch 79/200\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.6250 - loss: 0.7868\n",
      "Epoch 79: val_loss did not improve from 0.53400\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6845 - loss: 0.6593 - val_accuracy: 0.7073 - val_loss: 0.6302\n",
      "Epoch 80/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6868 - loss: 0.6337 \n",
      "Epoch 80: val_loss did not improve from 0.53400\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.6887 - loss: 0.6332 - val_accuracy: 0.7073 - val_loss: 0.6388\n",
      "Epoch 81/200\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.7031 - loss: 0.5908\n",
      "Epoch 81: val_loss did not improve from 0.53400\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.6903 - loss: 0.6409 - val_accuracy: 0.7073 - val_loss: 0.6457\n",
      "Epoch 82/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6772 - loss: 0.7035 \n",
      "Epoch 82: val_loss did not improve from 0.53400\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.6770 - loss: 0.7030 - val_accuracy: 0.7073 - val_loss: 0.6385\n",
      "Epoch 83/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6880 - loss: 0.6489\n",
      "Epoch 83: val_loss did not improve from 0.53400\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.6915 - loss: 0.6453 - val_accuracy: 0.7073 - val_loss: 0.6258\n",
      "Epoch 84/200\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.7344 - loss: 0.6030\n",
      "Epoch 84: val_loss did not improve from 0.53400\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7248 - loss: 0.6179 - val_accuracy: 0.7073 - val_loss: 0.6291\n",
      "Epoch 85/200\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.6875 - loss: 0.5716\n",
      "Epoch 85: val_loss did not improve from 0.53400\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7063 - loss: 0.6408 - val_accuracy: 0.7073 - val_loss: 0.6272\n",
      "Epoch 86/200\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.7812 - loss: 0.6059\n",
      "Epoch 86: val_loss did not improve from 0.53400\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7234 - loss: 0.6214 - val_accuracy: 0.7073 - val_loss: 0.6283\n",
      "Epoch 87/200\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.6250 - loss: 0.7440\n",
      "Epoch 87: val_loss did not improve from 0.53400\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6684 - loss: 0.6658 - val_accuracy: 0.7073 - val_loss: 0.6338\n",
      "Epoch 88/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6976 - loss: 0.6187 \n",
      "Epoch 88: val_loss did not improve from 0.53400\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6989 - loss: 0.6179 - val_accuracy: 0.7073 - val_loss: 0.6264\n",
      "Epoch 89/200\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.8281 - loss: 0.5092\n",
      "Epoch 89: val_loss did not improve from 0.53400\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7336 - loss: 0.5892 - val_accuracy: 0.7073 - val_loss: 0.6190\n",
      "Epoch 90/200\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 170ms/step - accuracy: 0.7188 - loss: 0.5684\n",
      "Epoch 90: val_loss did not improve from 0.53400\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.6967 - loss: 0.6271 - val_accuracy: 0.7073 - val_loss: 0.6293\n",
      "Epoch 91/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7143 - loss: 0.6005 \n",
      "Epoch 91: val_loss did not improve from 0.53400\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7110 - loss: 0.6034 - val_accuracy: 0.7073 - val_loss: 0.6296\n",
      "Epoch 92/200\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.5938 - loss: 0.7280\n",
      "Epoch 92: val_loss did not improve from 0.53400\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6779 - loss: 0.6422 - val_accuracy: 0.7073 - val_loss: 0.6390\n",
      "Epoch 93/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6920 - loss: 0.6040\n",
      "Epoch 93: val_loss did not improve from 0.53400\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6924 - loss: 0.6042 - val_accuracy: 0.7073 - val_loss: 0.6267\n",
      "Epoch 94/200\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.7656 - loss: 0.5407\n",
      "Epoch 94: val_loss did not improve from 0.53400\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7171 - loss: 0.6089 - val_accuracy: 0.7073 - val_loss: 0.6378\n",
      "Epoch 95/200\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.7031 - loss: 0.6375\n",
      "Epoch 95: val_loss did not improve from 0.53400\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7118 - loss: 0.6447 - val_accuracy: 0.7073 - val_loss: 0.6231\n",
      "Epoch 96/200\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.7500 - loss: 0.6435\n",
      "Epoch 96: val_loss did not improve from 0.53400\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7206 - loss: 0.6419 - val_accuracy: 0.7073 - val_loss: 0.6076\n",
      "Epoch 97/200\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.7188 - loss: 0.6645\n",
      "Epoch 97: val_loss did not improve from 0.53400\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7236 - loss: 0.6054 - val_accuracy: 0.7073 - val_loss: 0.6023\n",
      "Epoch 98/200\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 165ms/step - accuracy: 0.7188 - loss: 0.6679\n",
      "Epoch 98: val_loss did not improve from 0.53400\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7080 - loss: 0.6626 - val_accuracy: 0.7073 - val_loss: 0.6291\n",
      "Epoch 99/200\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.6719 - loss: 0.6082\n",
      "Epoch 99: val_loss did not improve from 0.53400\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.6984 - loss: 0.6225 - val_accuracy: 0.7073 - val_loss: 0.6466\n",
      "Epoch 100/200\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.7344 - loss: 0.6384\n",
      "Epoch 100: val_loss did not improve from 0.53400\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6976 - loss: 0.6429 - val_accuracy: 0.7073 - val_loss: 0.6490\n",
      "Epoch 101/200\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.7656 - loss: 0.5398\n",
      "Epoch 101: val_loss did not improve from 0.53400\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7251 - loss: 0.5983 - val_accuracy: 0.7073 - val_loss: 0.6267\n",
      "Epoch 102/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7085 - loss: 0.6289 \n",
      "Epoch 102: val_loss did not improve from 0.53400\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7095 - loss: 0.6279 - val_accuracy: 0.7073 - val_loss: 0.6159\n",
      "Epoch 103/200\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.6562 - loss: 0.6065\n",
      "Epoch 103: val_loss did not improve from 0.53400\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7059 - loss: 0.5937 - val_accuracy: 0.7073 - val_loss: 0.6231\n",
      "Epoch 104/200\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.7188 - loss: 0.5536\n",
      "Epoch 104: val_loss did not improve from 0.53400\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7301 - loss: 0.5757 - val_accuracy: 0.7073 - val_loss: 0.6187\n",
      "Epoch 105/200\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.7031 - loss: 0.6264\n",
      "Epoch 105: val_loss did not improve from 0.53400\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6996 - loss: 0.6160 - val_accuracy: 0.7073 - val_loss: 0.6591\n",
      "Epoch 106/200\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.6406 - loss: 0.5594\n",
      "Epoch 106: val_loss did not improve from 0.53400\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.6311 - loss: 0.6305 - val_accuracy: 0.7073 - val_loss: 0.6419\n",
      "Epoch 107/200\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.7188 - loss: 0.6193\n",
      "Epoch 107: val_loss did not improve from 0.53400\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7001 - loss: 0.6318 - val_accuracy: 0.7073 - val_loss: 0.6288\n",
      "Epoch 108/200\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.6875 - loss: 0.5544\n",
      "Epoch 108: val_loss did not improve from 0.53400\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.6964 - loss: 0.5770 - val_accuracy: 0.7073 - val_loss: 0.6248\n",
      "Epoch 109/200\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.7500 - loss: 0.5677\n",
      "Epoch 109: val_loss did not improve from 0.53400\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7225 - loss: 0.5954 - val_accuracy: 0.7073 - val_loss: 0.6210\n",
      "Epoch 110/200\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.7656 - loss: 0.5405\n",
      "Epoch 110: val_loss did not improve from 0.53400\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.7260 - loss: 0.5955 - val_accuracy: 0.7073 - val_loss: 0.6302\n",
      "Epoch 111/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7232 - loss: 0.5739\n",
      "Epoch 111: val_loss did not improve from 0.53400\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.7234 - loss: 0.5760 - val_accuracy: 0.7073 - val_loss: 0.6341\n",
      "Epoch 112/200\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.7500 - loss: 0.5818\n",
      "Epoch 112: val_loss did not improve from 0.53400\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7269 - loss: 0.6000 - val_accuracy: 0.7073 - val_loss: 0.6343\n",
      "Epoch 113/200\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 172ms/step - accuracy: 0.7188 - loss: 0.5790\n",
      "Epoch 113: val_loss did not improve from 0.53400\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.6942 - loss: 0.6305 - val_accuracy: 0.7073 - val_loss: 0.6389\n",
      "Epoch 114/200\n",
      "\u001b[1m5/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7146 - loss: 0.6105 \n",
      "Epoch 114: val_loss did not improve from 0.53400\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.7105 - loss: 0.6180 - val_accuracy: 0.7073 - val_loss: 0.6410\n",
      "Epoch 115/200\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.7656 - loss: 0.5587\n",
      "Epoch 115: val_loss did not improve from 0.53400\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.7364 - loss: 0.5596 - val_accuracy: 0.7073 - val_loss: 0.6357\n",
      "Epoch 116/200\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.6562 - loss: 0.7092\n",
      "Epoch 116: val_loss did not improve from 0.53400\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7060 - loss: 0.6219 - val_accuracy: 0.7073 - val_loss: 0.6442\n",
      "Epoch 117/200\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.6719 - loss: 0.6434\n",
      "Epoch 117: val_loss did not improve from 0.53400\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6979 - loss: 0.6308 - val_accuracy: 0.7073 - val_loss: 0.6381\n",
      "Epoch 118/200\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.8125 - loss: 0.4940\n",
      "Epoch 118: val_loss did not improve from 0.53400\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7368 - loss: 0.5906 - val_accuracy: 0.7073 - val_loss: 0.6225\n",
      "Epoch 119/200\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.7344 - loss: 0.5998\n",
      "Epoch 119: val_loss did not improve from 0.53400\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7135 - loss: 0.6152 - val_accuracy: 0.7073 - val_loss: 0.6385\n",
      "Epoch 120/200\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.6406 - loss: 0.6362\n",
      "Epoch 120: val_loss did not improve from 0.53400\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7025 - loss: 0.6057 - val_accuracy: 0.7073 - val_loss: 0.6457\n",
      "Epoch 121/200\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.7656 - loss: 0.5171\n",
      "Epoch 121: val_loss did not improve from 0.53400\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7225 - loss: 0.5813 - val_accuracy: 0.7073 - val_loss: 0.6451\n",
      "Epoch 122/200\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.7031 - loss: 0.5909\n",
      "Epoch 122: val_loss did not improve from 0.53400\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.7095 - loss: 0.6302 - val_accuracy: 0.7073 - val_loss: 0.6474\n",
      "Epoch 123/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7180 - loss: 0.5818 \n",
      "Epoch 123: val_loss did not improve from 0.53400\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.7168 - loss: 0.5845 - val_accuracy: 0.7073 - val_loss: 0.6395\n",
      "Epoch 124/200\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.6875 - loss: 0.5684\n",
      "Epoch 124: val_loss did not improve from 0.53400\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7064 - loss: 0.5946 - val_accuracy: 0.7073 - val_loss: 0.6465\n",
      "Epoch 125/200\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.7188 - loss: 0.5706\n",
      "Epoch 125: val_loss did not improve from 0.53400\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6917 - loss: 0.6312 - val_accuracy: 0.7073 - val_loss: 0.6493\n",
      "Epoch 126/200\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.7344 - loss: 0.5769\n",
      "Epoch 126: val_loss did not improve from 0.53400\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6958 - loss: 0.6252 - val_accuracy: 0.7073 - val_loss: 0.6403\n",
      "Epoch 127/200\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.7500 - loss: 0.5317\n",
      "Epoch 127: val_loss did not improve from 0.53400\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7171 - loss: 0.5867 - val_accuracy: 0.7073 - val_loss: 0.6367\n",
      "Epoch 128/200\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.6875 - loss: 0.5774\n",
      "Epoch 128: val_loss did not improve from 0.53400\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7030 - loss: 0.5826 - val_accuracy: 0.7073 - val_loss: 0.6370\n",
      "Epoch 129/200\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.7344 - loss: 0.5487\n",
      "Epoch 129: val_loss did not improve from 0.53400\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7041 - loss: 0.6054 - val_accuracy: 0.7073 - val_loss: 0.6379\n",
      "Epoch 130/200\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.7188 - loss: 0.7471\n",
      "Epoch 130: val_loss did not improve from 0.53400\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7096 - loss: 0.6503 - val_accuracy: 0.7073 - val_loss: 0.6334\n",
      "Epoch 131/200\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.7031 - loss: 0.5524\n",
      "Epoch 131: val_loss did not improve from 0.53400\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7133 - loss: 0.5890 - val_accuracy: 0.7073 - val_loss: 0.6307\n",
      "Epoch 132/200\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.7500 - loss: 0.5456\n",
      "Epoch 132: val_loss did not improve from 0.53400\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7165 - loss: 0.6133 - val_accuracy: 0.7073 - val_loss: 0.6422\n",
      "Epoch 133/200\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.6875 - loss: 0.5915\n",
      "Epoch 133: val_loss did not improve from 0.53400\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7172 - loss: 0.5789 - val_accuracy: 0.7073 - val_loss: 0.6379\n",
      "Epoch 134/200\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.8125 - loss: 0.4867\n",
      "Epoch 134: val_loss did not improve from 0.53400\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.7419 - loss: 0.5551 - val_accuracy: 0.7073 - val_loss: 0.6254\n",
      "Epoch 135/200\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.6875 - loss: 0.6665\n",
      "Epoch 135: val_loss did not improve from 0.53400\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.7150 - loss: 0.6188 - val_accuracy: 0.7073 - val_loss: 0.6280\n",
      "Epoch 136/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6656 - loss: 0.6528\n",
      "Epoch 136: val_loss did not improve from 0.53400\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.6718 - loss: 0.6462 - val_accuracy: 0.7073 - val_loss: 0.6254\n",
      "Epoch 137/200\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.7656 - loss: 0.5279\n",
      "Epoch 137: val_loss did not improve from 0.53400\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7122 - loss: 0.5959 - val_accuracy: 0.7073 - val_loss: 0.6134\n",
      "Epoch 138/200\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.7344 - loss: 0.5975\n",
      "Epoch 138: val_loss did not improve from 0.53400\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.6961 - loss: 0.6433 - val_accuracy: 0.7073 - val_loss: 0.6145\n",
      "Epoch 139/200\n",
      "\u001b[1m4/6\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7741 - loss: 0.5608\n",
      "Epoch 139: val_loss did not improve from 0.53400\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.7512 - loss: 0.5937 - val_accuracy: 0.7073 - val_loss: 0.6041\n",
      "Epoch 140/200\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.6875 - loss: 0.6153\n",
      "Epoch 140: val_loss did not improve from 0.53400\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7006 - loss: 0.6204 - val_accuracy: 0.7073 - val_loss: 0.6096\n",
      "Epoch 141/200\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.7344 - loss: 0.5771\n",
      "Epoch 141: val_loss did not improve from 0.53400\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7204 - loss: 0.5992 - val_accuracy: 0.7073 - val_loss: 0.6141\n",
      "Epoch 142/200\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.7812 - loss: 0.5956\n",
      "Epoch 142: val_loss did not improve from 0.53400\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7048 - loss: 0.6107 - val_accuracy: 0.7073 - val_loss: 0.6183\n",
      "Epoch 143/200\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.6406 - loss: 0.6421\n",
      "Epoch 143: val_loss did not improve from 0.53400\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6822 - loss: 0.6197 - val_accuracy: 0.7073 - val_loss: 0.6136\n",
      "Epoch 144/200\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.7500 - loss: 0.5409\n",
      "Epoch 144: val_loss did not improve from 0.53400\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7337 - loss: 0.5706 - val_accuracy: 0.7073 - val_loss: 0.6042\n",
      "Epoch 145/200\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.6875 - loss: 0.5298\n",
      "Epoch 145: val_loss did not improve from 0.53400\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.7043 - loss: 0.5904 - val_accuracy: 0.7073 - val_loss: 0.6108\n",
      "Epoch 146/200\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.7188 - loss: 0.6209\n",
      "Epoch 146: val_loss did not improve from 0.53400\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7078 - loss: 0.6099 - val_accuracy: 0.7073 - val_loss: 0.6273\n",
      "Epoch 147/200\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.6875 - loss: 0.5938\n",
      "Epoch 147: val_loss did not improve from 0.53400\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.7170 - loss: 0.5902 - val_accuracy: 0.7073 - val_loss: 0.6109\n",
      "Epoch 148/200\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.6875 - loss: 0.5796\n",
      "Epoch 148: val_loss did not improve from 0.53400\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7093 - loss: 0.5977 - val_accuracy: 0.7073 - val_loss: 0.5971\n",
      "Epoch 149/200\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.7500 - loss: 0.5800\n",
      "Epoch 149: val_loss did not improve from 0.53400\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7276 - loss: 0.5971 - val_accuracy: 0.7073 - val_loss: 0.5987\n",
      "Epoch 150/200\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.7031 - loss: 0.5871\n",
      "Epoch 150: val_loss did not improve from 0.53400\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.7188 - loss: 0.6008 - val_accuracy: 0.7073 - val_loss: 0.6238\n",
      "Epoch 151/200\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.7031 - loss: 0.5724\n",
      "Epoch 151: val_loss did not improve from 0.53400\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7197 - loss: 0.5876 - val_accuracy: 0.7073 - val_loss: 0.6248\n",
      "Epoch 152/200\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.6719 - loss: 0.6464\n",
      "Epoch 152: val_loss did not improve from 0.53400\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.6974 - loss: 0.6434 - val_accuracy: 0.7073 - val_loss: 0.6165\n",
      "Epoch 153/200\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.6875 - loss: 0.6008\n",
      "Epoch 153: val_loss did not improve from 0.53400\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6966 - loss: 0.5969 - val_accuracy: 0.7073 - val_loss: 0.6079\n",
      "Epoch 154/200\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.6250 - loss: 0.6726\n",
      "Epoch 154: val_loss did not improve from 0.53400\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.6753 - loss: 0.6541 - val_accuracy: 0.7073 - val_loss: 0.6020\n",
      "Epoch 155/200\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.7031 - loss: 0.5652\n",
      "Epoch 155: val_loss did not improve from 0.53400\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7143 - loss: 0.5833 - val_accuracy: 0.7073 - val_loss: 0.5927\n",
      "Epoch 156/200\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.7344 - loss: 0.5895\n",
      "Epoch 156: val_loss did not improve from 0.53400\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.7169 - loss: 0.6063 - val_accuracy: 0.7073 - val_loss: 0.5945\n",
      "Epoch 157/200\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.6719 - loss: 0.6867\n",
      "Epoch 157: val_loss did not improve from 0.53400\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7032 - loss: 0.6183 - val_accuracy: 0.7073 - val_loss: 0.6036\n",
      "Epoch 158/200\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.6406 - loss: 0.6574\n",
      "Epoch 158: val_loss did not improve from 0.53400\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6886 - loss: 0.6049 - val_accuracy: 0.7073 - val_loss: 0.6096\n",
      "Epoch 159/200\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.7812 - loss: 0.6208\n",
      "Epoch 159: val_loss did not improve from 0.53400\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7362 - loss: 0.5763 - val_accuracy: 0.7073 - val_loss: 0.6069\n",
      "Epoch 160/200\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.7500 - loss: 0.5505\n",
      "Epoch 160: val_loss did not improve from 0.53400\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.7388 - loss: 0.5799 - val_accuracy: 0.7073 - val_loss: 0.6035\n",
      "Epoch 161/200\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.6562 - loss: 0.6516\n",
      "Epoch 161: val_loss did not improve from 0.53400\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6986 - loss: 0.5968 - val_accuracy: 0.7073 - val_loss: 0.6087\n",
      "Epoch 162/200\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.6875 - loss: 0.5887\n",
      "Epoch 162: val_loss did not improve from 0.53400\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7013 - loss: 0.6046 - val_accuracy: 0.7073 - val_loss: 0.6053\n",
      "Epoch 163/200\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.7188 - loss: 0.5572\n",
      "Epoch 163: val_loss did not improve from 0.53400\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.6960 - loss: 0.5854 - val_accuracy: 0.7073 - val_loss: 0.6019\n",
      "Epoch 164/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6938 - loss: 0.5836\n",
      "Epoch 164: val_loss did not improve from 0.53400\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.6947 - loss: 0.5828 - val_accuracy: 0.7073 - val_loss: 0.5891\n",
      "Epoch 165/200\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.7188 - loss: 0.6098\n",
      "Epoch 165: val_loss did not improve from 0.53400\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6965 - loss: 0.6141 - val_accuracy: 0.7073 - val_loss: 0.5961\n",
      "Epoch 166/200\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.7188 - loss: 0.6352\n",
      "Epoch 166: val_loss did not improve from 0.53400\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7121 - loss: 0.6146 - val_accuracy: 0.7073 - val_loss: 0.5954\n",
      "Epoch 167/200\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.7188 - loss: 0.5871\n",
      "Epoch 167: val_loss did not improve from 0.53400\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7137 - loss: 0.6208 - val_accuracy: 0.7073 - val_loss: 0.6144\n",
      "Epoch 168/200\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 155ms/step - accuracy: 0.6250 - loss: 0.6215\n",
      "Epoch 168: val_loss did not improve from 0.53400\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.6918 - loss: 0.5991 - val_accuracy: 0.7073 - val_loss: 0.6118\n",
      "Epoch 169/200\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.7344 - loss: 0.5910\n",
      "Epoch 169: val_loss did not improve from 0.53400\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7211 - loss: 0.5885 - val_accuracy: 0.7073 - val_loss: 0.6082\n",
      "Epoch 170/200\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.6875 - loss: 0.5840\n",
      "Epoch 170: val_loss did not improve from 0.53400\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7126 - loss: 0.5888 - val_accuracy: 0.7073 - val_loss: 0.6054\n",
      "Epoch 171/200\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.7188 - loss: 0.6108\n",
      "Epoch 171: val_loss did not improve from 0.53400\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7194 - loss: 0.5800 - val_accuracy: 0.7073 - val_loss: 0.6017\n",
      "Epoch 172/200\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.6875 - loss: 0.6415\n",
      "Epoch 172: val_loss did not improve from 0.53400\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7001 - loss: 0.6309 - val_accuracy: 0.7073 - val_loss: 0.6014\n",
      "Epoch 173/200\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.7812 - loss: 0.5053\n",
      "Epoch 173: val_loss did not improve from 0.53400\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7462 - loss: 0.5648 - val_accuracy: 0.7073 - val_loss: 0.6017\n",
      "Epoch 174/200\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.7344 - loss: 0.5335\n",
      "Epoch 174: val_loss did not improve from 0.53400\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7236 - loss: 0.5692 - val_accuracy: 0.7073 - val_loss: 0.6144\n",
      "Epoch 175/200\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.6719 - loss: 0.6262\n",
      "Epoch 175: val_loss did not improve from 0.53400\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6889 - loss: 0.6140 - val_accuracy: 0.7073 - val_loss: 0.6206\n",
      "Epoch 176/200\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.8281 - loss: 0.4972\n",
      "Epoch 176: val_loss did not improve from 0.53400\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7418 - loss: 0.5664 - val_accuracy: 0.7073 - val_loss: 0.5997\n",
      "Epoch 177/200\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7036 - loss: 0.5655\n",
      "Epoch 177: val_loss did not improve from 0.53400\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.7040 - loss: 0.5663 - val_accuracy: 0.7073 - val_loss: 0.5983\n",
      "Epoch 178/200\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.6875 - loss: 0.5833\n",
      "Epoch 178: val_loss did not improve from 0.53400\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7093 - loss: 0.5915 - val_accuracy: 0.7073 - val_loss: 0.6048\n",
      "Epoch 179/200\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.7500 - loss: 0.5298\n",
      "Epoch 179: val_loss did not improve from 0.53400\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7232 - loss: 0.5680 - val_accuracy: 0.7073 - val_loss: 0.6062\n",
      "Epoch 180/200\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.8438 - loss: 0.4887\n",
      "Epoch 180: val_loss did not improve from 0.53400\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7398 - loss: 0.5604 - val_accuracy: 0.7073 - val_loss: 0.6001\n",
      "Epoch 181/200\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.7344 - loss: 0.5878\n",
      "Epoch 181: val_loss did not improve from 0.53400\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.7142 - loss: 0.5996 - val_accuracy: 0.7073 - val_loss: 0.5896\n",
      "Epoch 182/200\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.7656 - loss: 0.5361\n",
      "Epoch 182: val_loss did not improve from 0.53400\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7377 - loss: 0.5882 - val_accuracy: 0.7073 - val_loss: 0.5903\n",
      "Epoch 183/200\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.7344 - loss: 0.5952\n",
      "Epoch 183: val_loss did not improve from 0.53400\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7137 - loss: 0.5917 - val_accuracy: 0.7073 - val_loss: 0.5966\n",
      "Epoch 184/200\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.6250 - loss: 0.7563\n",
      "Epoch 184: val_loss did not improve from 0.53400\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6929 - loss: 0.6313 - val_accuracy: 0.7073 - val_loss: 0.5785\n",
      "Epoch 185/200\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.6719 - loss: 0.6293\n",
      "Epoch 185: val_loss did not improve from 0.53400\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7059 - loss: 0.6145 - val_accuracy: 0.7073 - val_loss: 0.5679\n",
      "Epoch 186/200\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.7500 - loss: 0.5236\n",
      "Epoch 186: val_loss did not improve from 0.53400\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7222 - loss: 0.5740 - val_accuracy: 0.7073 - val_loss: 0.5697\n",
      "Epoch 187/200\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.6875 - loss: 0.6897\n",
      "Epoch 187: val_loss did not improve from 0.53400\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.7030 - loss: 0.6092 - val_accuracy: 0.7073 - val_loss: 0.5797\n",
      "Epoch 188/200\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - accuracy: 0.7188 - loss: 0.5649\n",
      "Epoch 188: val_loss did not improve from 0.53400\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7126 - loss: 0.5768 - val_accuracy: 0.7073 - val_loss: 0.5824\n",
      "Epoch 189/200\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.7656 - loss: 0.5307\n",
      "Epoch 189: val_loss did not improve from 0.53400\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7270 - loss: 0.5669 - val_accuracy: 0.7073 - val_loss: 0.5886\n",
      "Epoch 190/200\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.7969 - loss: 0.4751\n",
      "Epoch 190: val_loss did not improve from 0.53400\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7475 - loss: 0.5588 - val_accuracy: 0.7073 - val_loss: 0.5866\n",
      "Epoch 191/200\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.6562 - loss: 0.6388\n",
      "Epoch 191: val_loss did not improve from 0.53400\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7076 - loss: 0.5960 - val_accuracy: 0.7073 - val_loss: 0.6009\n",
      "Epoch 192/200\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.7344 - loss: 0.5373\n",
      "Epoch 192: val_loss did not improve from 0.53400\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7174 - loss: 0.5967 - val_accuracy: 0.7073 - val_loss: 0.6152\n",
      "Epoch 193/200\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.7969 - loss: 0.5415\n",
      "Epoch 193: val_loss did not improve from 0.53400\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7257 - loss: 0.5922 - val_accuracy: 0.7073 - val_loss: 0.6131\n",
      "Epoch 194/200\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.6875 - loss: 0.6734\n",
      "Epoch 194: val_loss did not improve from 0.53400\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7158 - loss: 0.5985 - val_accuracy: 0.7073 - val_loss: 0.6072\n",
      "Epoch 195/200\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.7500 - loss: 0.5941\n",
      "Epoch 195: val_loss did not improve from 0.53400\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.7308 - loss: 0.5881 - val_accuracy: 0.7073 - val_loss: 0.5915\n",
      "Epoch 196/200\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - accuracy: 0.6875 - loss: 0.6757\n",
      "Epoch 196: val_loss did not improve from 0.53400\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7017 - loss: 0.5941 - val_accuracy: 0.7073 - val_loss: 0.6029\n",
      "Epoch 197/200\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.7031 - loss: 0.5378\n",
      "Epoch 197: val_loss did not improve from 0.53400\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7037 - loss: 0.5751 - val_accuracy: 0.7073 - val_loss: 0.6224\n",
      "Epoch 198/200\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.7344 - loss: 0.5824\n",
      "Epoch 198: val_loss did not improve from 0.53400\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7321 - loss: 0.5832 - val_accuracy: 0.7073 - val_loss: 0.6075\n",
      "Epoch 199/200\n",
      "\u001b[1m1/6\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.6562 - loss: 0.6616\n",
      "Epoch 199: val_loss did not improve from 0.53400\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6933 - loss: 0.6034 - val_accuracy: 0.7073 - val_loss: 0.5823\n",
      "Epoch 200/200\n",
      "\u001b[1m4/6\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7536 - loss: 0.5321\n",
      "Epoch 200: val_loss did not improve from 0.53400\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.7395 - loss: 0.5537 - val_accuracy: 0.7073 - val_loss: 0.5672\n",
      "Iteration complet in time:  0:00:54.090299\n"
     ]
    }
   ],
   "source": [
    "## train my model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from datetime import datetime\n",
    "\n",
    "num_epochs = 200 #100\n",
    "num_batch_size = 64 #32\n",
    "\n",
    "chechpointer = ModelCheckpoint(filepath='saved_models/audio_classification.keras',verbose=1,save_best_only=True)\n",
    "start = datetime.now()\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=num_batch_size, epochs=num_epochs, validation_data=(X_test, y_test), callbacks=[chechpointer])\n",
    "\n",
    "duration = datetime.now() - start\n",
    "print('Iteration complet in time: ', duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "057309d0-0f00-4ce5-9d57-2e94edd46eec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.707317054271698\n"
     ]
    }
   ],
   "source": [
    "test_accuracy=model.evaluate(X_test, y_test, verbose=0)\n",
    "print(test_accuracy[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32204e5b-2d64-484b-b064-d8f47f8308d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ef8801-02b9-4305-a767-da33b5cc9d58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d34507-84ea-4a16-9011-3c21fe3cfb44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc2a1e9-9bff-4575-bda5-e977d59a3979",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b4b21ca-c76e-4dd2-8c1a-3c5fb8c536f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
